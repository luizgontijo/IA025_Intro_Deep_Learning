{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/luizgontijo/IA025_Intro_Deep_Learning/blob/main/ex10_attention_causal_mask.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jOdQB41_4ZxG",
        "outputId": "db69a2a2-b34a-4f1f-a56e-38259d8ecbc0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Meu nome é Luiz Fernando da Costa Gontijo\n"
          ]
        }
      ],
      "source": [
        "nome = 'Luiz Fernando da Costa Gontijo'\n",
        "print(f'Meu nome é {nome}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2IbuChoAPMEn"
      },
      "source": [
        "#  Exercício: Modelo de Linguagem com auto-atenção"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p_DBb0-Klwf2"
      },
      "source": [
        "Este exercício é similar ao da Aula 8, mas iremos agora treinar uma rede neural com **duas camadas** de auto-atenção **causais** para prever a próxima palavra de um texto, data as palavras anteriores como entrada. \n",
        "\n",
        "Iremos também trabalhar com sequencias de tamanho variável.\n",
        "\n",
        "Na camada de auto-atenção, não se esqueça de implementar:\n",
        "- Embeddings de posição\n",
        "- Projeções lineares (WQ, WK, WV, WO)\n",
        "- Conexões residuais\n",
        "- Camada de feed forward (2-layer MLP)\n",
        "\n",
        "\n",
        "O dataset usado neste exercício (BrWaC) possui um tamanho razoável e você vai precisar rodar seus experimentos com GPU.\n",
        "\n",
        "Alguns conselhos úteis:\n",
        "- **ATENÇÃO:** o dataset é bem grande. Não dê comando de imprimí-lo.\n",
        "- Durante a depuração, faça seu dataset ficar bem pequeno, para que a depuração seja mais rápida e não precise de GPU. Somente ligue a GPU quando o seu laço de treinamento já está funcionando\n",
        "- Não deixe para fazer esse exercício na véspera. Ele é trabalhoso."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3twP0YJC4jmJ",
        "outputId": "380cc117-7b40-4779-e29c-a1feebfc34ff"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.19.2-py3-none-any.whl (4.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.2 MB 14.5 MB/s \n",
            "\u001b[?25hCollecting pyyaml>=5.1\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 13.3 MB/s \n",
            "\u001b[?25hCollecting tokenizers!=0.11.3,<0.13,>=0.11.1\n",
            "  Downloading tokenizers-0.12.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.6 MB 50.2 MB/s \n",
            "\u001b[?25hCollecting huggingface-hub<1.0,>=0.1.0\n",
            "  Downloading huggingface_hub-0.7.0-py3-none-any.whl (86 kB)\n",
            "\u001b[K     |████████████████████████████████| 86 kB 3.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.7.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.11.4)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.2.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.5.18.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Installing collected packages: pyyaml, tokenizers, huggingface-hub, transformers\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed huggingface-hub-0.7.0 pyyaml-6.0 tokenizers-0.12.1 transformers-4.19.2\n"
          ]
        }
      ],
      "source": [
        "# iremos utilizar a biblioteca dos transformers para ter acesso ao tokenizador do BERT.\n",
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YnyhJZtTRNMx"
      },
      "source": [
        "## Importação dos pacotes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qlIOVCajPWcU"
      },
      "outputs": [],
      "source": [
        "import collections\n",
        "import itertools\n",
        "import functools\n",
        "import math\n",
        "import random\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "from torch.utils.data import DataLoader\n",
        "from tqdm import tqdm_notebook\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w9f3PfifAwpU",
        "outputId": "725bf80e-8668-4036-c31a-5690e7a2931d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Thu Jun  9 01:57:59 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   50C    P8    10W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "# Check which GPU we are using\n",
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "whTCe2i7AtoV",
        "outputId": "3adf8b04-7569-4617-a674-e73c1f3fa609"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cuda:0\n"
          ]
        }
      ],
      "source": [
        "if torch.cuda.is_available(): \n",
        "   dev = \"cuda:0\"\n",
        "else: \n",
        "   dev = \"cpu\"\n",
        "device = torch.device(dev)\n",
        "print('Using {}'.format(device))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ZfxgV2DUk58"
      },
      "source": [
        "## Implementação do MyDataset"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# tentar esse dataset para verificar o overfitting\n",
        "\n",
        "from typing import List\n",
        "\n",
        "\n",
        "def tokenize(text: str, tokenizer):\n",
        "    return tokenizer(text, return_tensors=None, add_special_tokens=False).input_ids\n",
        "\n",
        "\n",
        "class MyDataset():\n",
        "    def __init__(self, texts: List[str], tokenizer, max_seq_length: int):\n",
        "        # Escreva seu código aqui\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_seq_length = max_seq_length\n",
        "        self.features = self._token_window(texts)\n",
        "\n",
        "    def _token_window(self, texts):\n",
        "        feat = []\n",
        "        y = []\n",
        "        # bucle para ler cada uma das frases de entrada\n",
        "\n",
        "        # Dataloader inspirado no notebook do Pedro Gengo\n",
        "        for text in texts:\n",
        "          # tokeniza uma frase\n",
        "          tokens_from_text = tokenize(f'[CLS]{text}', self.tokenizer)\n",
        "          tokens_from_text +=  [tokenizer.vocab['[PAD]']] * max(0, 1 + self.max_seq_length - len(tokens_from_text))\n",
        "          for i in range(0, len(tokens_from_text)-1, self.max_seq_length): \n",
        "            if i+self.max_seq_length < len(tokens_from_text):\n",
        "              feat.append(tokens_from_text[i:i+self.max_seq_length+1])\n",
        "            else:\n",
        "              feat.append(tokens_from_text[-self.max_seq_length-1:])\n",
        "        return torch.tensor(feat).long()\n",
        "\n",
        "    def __len__(self):\n",
        "        # Escreva seu código aqui\n",
        "        return len(self.features)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # Escreva seu código aqui\n",
        "        feat = self.features[idx]\n",
        "        #print(feat)\n",
        "        return feat[:-1], feat[1:]"
      ],
      "metadata": {
        "id": "2FT5vJkCooWY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wew-gFbWeBTq"
      },
      "source": [
        "## Testando se a implementação do MyDataset está correta"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6Lczd7GfUwRK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 177,
          "referenced_widgets": [
            "469d829b091c415fbc1df6af5a156f52",
            "026d500169cd4b3286077c782974d22e",
            "2180b993e80b40d9ad50f89d11f55670",
            "112cda068f2f42ddb17dbfd6af55c6ee",
            "4ebffc8f8b0e47f7ad1c0acbde55e5c0",
            "81efbe5f372e47ed8466b0ad6c809fe1",
            "582526328d2c43cfba5bef998eefaf96",
            "bdf2718ed9584dcf8af28a64172a1017",
            "ec8fc46745c74caa84e2355ce40700ed",
            "63bc706e98254b879e6b9106b4a39e88",
            "d452f6bff54c4b2584dbc2230e8653b3",
            "ccd575a5c08349148876f656b0120151",
            "6133f2f492224a9086f86d2235c895bc",
            "37aa74ff8e174730b8e9a38ebad2f973",
            "f3c5b23a935f4f36a8bc417d37ff9810",
            "6913f4eae703454b8f4941b41dc4fbbf",
            "f5a196b261ef43d8926e885f76aefcff",
            "146a65801d8442139e71647c8fbaee20",
            "57bb0716cf0247619f1998e7ab759e94",
            "160e78b755bc4adf88885e9d4adb2928",
            "f91e1bd87c224966bc1bd69d8f158d88",
            "5f624b6948fd49fb82f81771891fb887",
            "b5b920fd4a6a449999b313c56aea0028",
            "654b49da395d4049bba857d50c34883a",
            "7cc4ba677b334b81b6092dec5c1903a9",
            "15bc9c7c17a3476c85cb75b8259f51df",
            "7d36c8c53c2f450ab97a7d8b18f6a1d4",
            "fa6f41d376ff4e27be37508d89c22d25",
            "1aee1a1f641e4448b8c2cb8b5f4acad9",
            "5e0d9b02d5544c798dc8f5d5ebb0bc2f",
            "be7f29d65e14485eb74832eca163cd51",
            "8211acc3a6f34e95a8d414b5fe80c24a",
            "723b019276ed4e2bb80fbb5f2fd02737",
            "d1cdc514009e43ffad8fedb83e3395c7",
            "9e85c28c5b8147938e33090b296629d7",
            "4ffc3f6ff2174ed48d3872eaaee6ef21",
            "e8c587241d14400ea298911c352c8557",
            "e72f8579fbd4441f92bae305de84a3a2",
            "8495d49fdca241c1905eb8916d99de0e",
            "12079446e9cf4f73bd1ee19fb5930611",
            "f9e63bf9ee2246628fb975187dd10de8",
            "a719adc95f6e4cf7baa71068b5480956",
            "d2367d1ec3c2422cb0f6d8cf0c38cee7",
            "46c2c396d77c41759fbb31c44e99dc1f",
            "8aa4170b33204405b01fc68db3b960c3",
            "875190f4b8e74b2e856187625e7b93d9",
            "f0e09963c89b42e1a5202891380515d2",
            "5785b52c256e43ae8908e747b66e2a30",
            "ce3e0683d3a649c48a062d88d2753171",
            "bbb6942286ca44219eabe5e3ca83dc19",
            "cfeb8653f51d4c4db0e290ea19b70c96",
            "711425a7902d4e319cf66a71bd8c736c",
            "a78adcf4b5244c9daae9f3c0135b3539",
            "35b3c6968f3345af914a588110abf9ab",
            "80870b89b7e24f30bdb31fa891e3d7f7"
          ]
        },
        "outputId": "37eebf32-f0c1-436d-9e5e-1b0fbde0cb96"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/205k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "469d829b091c415fbc1df6af5a156f52"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/2.00 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ccd575a5c08349148876f656b0120151"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/112 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b5b920fd4a6a449999b313c56aea0028"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/43.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d1cdc514009e43ffad8fedb83e3395c7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/647 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8aa4170b33204405b01fc68db3b960c3"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "from transformers import BertTokenizer\n",
        "\n",
        "tokenizer = BertTokenizer.from_pretrained(\"neuralmind/bert-base-portuguese-cased\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KW4gShbvLRlP",
        "outputId": "4b49845f-f16c-452f-8625-75432774ebed"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Passou no assert de tamanho do dataset.\n",
            "first_batch_input: tensor([[  101,  3396, 10303,   125, 13239,     0,     0,     0,     0],\n",
            "        [  101,  1660,  5971,   785,   125,  1847, 13779, 15616,     0],\n",
            "        [  101,   787,   253,  2996, 22280,   221, 18165,   122,  1028],\n",
            "        [  221, 18165,   122,  1028,  4486,   123,   325,   864,  4486]])\n",
            "first_batch_target: tensor([[ 3396, 10303,   125, 13239,     0,     0,     0,     0,     0],\n",
            "        [ 1660,  5971,   785,   125,  1847, 13779, 15616,     0,     0],\n",
            "        [  787,   253,  2996, 22280,   221, 18165,   122,  1028,  4486],\n",
            "        [18165,   122,  1028,  4486,   123,   325,   864,  4486,  1755]])\n"
          ]
        }
      ],
      "source": [
        "dummy_texts = ['Eu gosto de correr', 'Ela gosta muito de comer pizza', 'Ele é feio para dormir e outras coisas a mais três coisas diferentes']\n",
        "\n",
        "dummy_dataset = MyDataset(texts=dummy_texts, tokenizer=tokenizer, max_seq_length=9)\n",
        "dummy_loader = DataLoader(dummy_dataset, batch_size=6, shuffle=False)\n",
        "#assert len(dummy_dataset) == 2\n",
        "print('Passou no assert de tamanho do dataset.')\n",
        "\n",
        "first_batch_input, first_batch_target = next(iter(dummy_loader))\n",
        "\n",
        "print(f'first_batch_input: {first_batch_input}')\n",
        "print(f'first_batch_target: {first_batch_target}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8r7jBFFUeApe",
        "outputId": "e53158c1-e69e-46b9-cf0b-af0aaeea6360"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Passou no assert de tamanho do dataset.\n",
            "meu batch: torch.int64\n",
            "batch correto: torch.int64\n",
            "Passou no assert de dataset.\n"
          ]
        }
      ],
      "source": [
        "from transformers import BertTokenizer\n",
        "\n",
        "tokenizer = BertTokenizer.from_pretrained(\"neuralmind/bert-base-portuguese-cased\")\n",
        "\n",
        "dummy_texts = ['Eu gosto de correr', 'Ela gosta muito de comer pizza']\n",
        "\n",
        "dummy_dataset = MyDataset(texts=dummy_texts, tokenizer=tokenizer, max_seq_length=9)\n",
        "dummy_loader = DataLoader(dummy_dataset, batch_size=6, shuffle=False)\n",
        "assert len(dummy_dataset) == 2\n",
        "print('Passou no assert de tamanho do dataset.')\n",
        "\n",
        "first_batch_input, first_batch_target = next(iter(dummy_loader))\n",
        "\n",
        "correct_first_batch_input = torch.LongTensor(\n",
        "    [[  101,  3396, 10303,   125, 13239,     0,     0,     0,     0],\n",
        "     [  101,  1660,  5971,   785,   125,  1847, 13779, 15616,     0]])\n",
        "\n",
        "correct_first_batch_target = torch.LongTensor(\n",
        "    [[ 3396, 10303,   125, 13239,     0,     0,     0,     0,     0],\n",
        "     [ 1660,  5971,   785,   125,  1847, 13779, 15616,     0,     0]])\n",
        "\n",
        "print(f'meu batch: {first_batch_input.dtype}')\n",
        "print(f'batch correto: {correct_first_batch_input.dtype}')\n",
        "\n",
        "assert torch.equal(first_batch_input, correct_first_batch_input)\n",
        "assert torch.equal(first_batch_target, correct_first_batch_target)\n",
        "\n",
        "print('Passou no assert de dataset.')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4LfrHHouleJ0"
      },
      "source": [
        "# Carregamento do dataset "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V2vFWjsSkmop"
      },
      "source": [
        "Iremos usar uma pequena amostra do dataset [BrWaC](https://www.inf.ufrgs.br/pln/wiki/index.php?title=BrWaC) para treinar e avaliar nosso modelo de linguagem."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vGlN1WqrXPA6",
        "outputId": "3d2a0b0e-c3a5-425b-e492-e15a6ae68983"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-06-09 01:58:13--  https://storage.googleapis.com/unicamp-dl/ia025a_2022s1/aula9/sample-1gb.txt\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 172.217.0.48, 172.217.2.112, 142.250.65.80, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|172.217.0.48|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1230909256 (1.1G) [text/plain]\n",
            "Saving to: ‘sample-1gb.txt’\n",
            "\n",
            "sample-1gb.txt      100%[===================>]   1.15G   130MB/s    in 7.9s    \n",
            "\n",
            "2022-06-09 01:58:21 (148 MB/s) - ‘sample-1gb.txt’ saved [1230909256/1230909256]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget -nc https://storage.googleapis.com/unicamp-dl/ia025a_2022s1/aula9/sample-1gb.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gxa_4gmiA-wE",
        "outputId": "1335a0b7-cc77-4326-d23f-007d4c84781e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Read 250000 lines.\n",
            "Truncating to 700 lines.\n"
          ]
        }
      ],
      "source": [
        "# Load datasets\n",
        "max_seq_length = 9\n",
        "\n",
        "train_examples = 500\n",
        "valid_examples = 100\n",
        "test_examples = 100\n",
        "\n",
        "texts = open('sample-1gb.txt').readlines()\n",
        "\n",
        "print(f'Read {len(texts)} lines.')\n",
        "\n",
        "max_lines = train_examples + valid_examples + test_examples\n",
        "print(f'Truncating to {max_lines} lines.')\n",
        "texts = texts[:max_lines]\n",
        "\n",
        "training_texts = texts[:-(valid_examples + test_examples)]\n",
        "valid_texts = texts[-(valid_examples + test_examples):-test_examples]\n",
        "test_texts = texts[-test_examples:]\n",
        "\n",
        "training_dataset = MyDataset(texts=training_texts, tokenizer=tokenizer, max_seq_length=max_seq_length)\n",
        "valid_dataset = MyDataset(texts=valid_texts, tokenizer=tokenizer, max_seq_length=max_seq_length)\n",
        "test_dataset = MyDataset(texts=test_texts, tokenizer=tokenizer, max_seq_length=max_seq_length)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KCSGJ5m7py4c",
        "outputId": "720a45fb-285c-44c5-ee39-c77fb8fd0c2f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training examples: 76178\n",
            "valid examples: 10136\n",
            "test examples: 9566\n"
          ]
        }
      ],
      "source": [
        "print(f'training examples: {len(training_dataset)}')\n",
        "print(f'valid examples: {len(valid_dataset)}')\n",
        "print(f'test examples: {len(test_dataset)}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J_Jwu4O9MoQV"
      },
      "outputs": [],
      "source": [
        "class LanguageModel(torch.nn.Module):\n",
        "\n",
        "    def __init__(self, vocab_size: int, max_seq_length: int, dim: int, n_layers: int, pad_token_id: int):\n",
        "        \"\"\"\n",
        "        Implements the Self-attention, decoder-only.\"\n",
        "\n",
        "        Args:\n",
        "            vocab_size (int): Size of the input vocabulary.\n",
        "            max_seq_length (int): Size of the sequence to consider as context for prediction.\n",
        "            dim (int): Dimension of the embedding layer for each word in the context.\n",
        "            n_layers (int): number of self-attention layers.\n",
        "            pad_token_id (int): id of the pad token that will be ignored in the attention.\n",
        "        \"\"\"\n",
        "        # Escreva seu código aqui.\n",
        "\n",
        "        super().__init__()\n",
        "\n",
        "        self.vocab_size = vocab_size\n",
        "        self.max_seq_length = max_seq_length\n",
        "        self.dim = dim\n",
        "        self.n_layers = n_layers\n",
        "        self.pad_token_id = pad_token_id\n",
        "\n",
        "        self.embedding_layer = torch.nn.Embedding(self.vocab_size, self.dim)\n",
        "        self.positional_embeddings = torch.nn.Linear(self.dim, self.max_seq_length, bias=False)\n",
        "\n",
        "        self.W_q = torch.nn.Linear(self.dim,self.dim,bias=False) \n",
        "        self.W_k = torch.nn.Linear(self.dim,self.dim,bias=False) \n",
        "        self.W_v = torch.nn.Linear(self.dim,self.dim,bias=False) \n",
        "        self.W_o = torch.nn.Linear(self.dim,self.dim,bias=False) \n",
        "        \n",
        "        hidden_size = 2*self.dim\n",
        "        #self.feed_forward = torch.nn.Sequential(nn.Linear(self.max_seq_length*self.dim, hidden_size),\n",
        "         #                                       nn.Dropout(0.2),\n",
        "         #                                       nn.ReLU(),\n",
        "         #                                       nn.Linear(hidden_size,self.max_seq_length*vocab_size))\n",
        "\n",
        "        hidden_layer = 64\n",
        "        self.linear1 = nn.Linear(self.max_seq_length*self.dim, hidden_layer)\n",
        "        self.linear2 = nn.Linear(hidden_layer, self.max_seq_length*self.vocab_size, bias=False)\n",
        "        self.tanh1 = nn.Tanh() # testar resultado\n",
        "        self.relu1 = nn.ReLU()\n",
        "        self.relu2 = nn.ReLU()\n",
        "        \n",
        "        # definir a máscara do pad\n",
        "        #self.mask_pad = self.pad_token_id != 0\n",
        "\n",
        "        # máscara causal\n",
        "        causal_mask = torch.ones(max_seq_length,max_seq_length)\n",
        "        causal_mask = torch.tril(causal_mask)\n",
        "        self.causal_mask = causal_mask.bool()\n",
        "\n",
        "\n",
        "    #Auxílio do código do Gabriel Lopes\n",
        "    def Attention(self, q, k, v, mask_padc):\n",
        "        scores = torch.matmul(q, k.transpose(-2,-1))#  [B,L,L]\n",
        "        scores = scores/math.sqrt(self.dim)\n",
        "\n",
        "        scores = scores.masked_fill(mask_padc == 0, -float(\"inf\"))\n",
        "\n",
        "        probs = nn.functional.softmax(scores, dim = -1)  \n",
        "\n",
        "        output = torch.matmul(probs, v)#.transpose(1, 2) \n",
        "        #E  = torch.matmul(probs, v) # [B,L,E]\n",
        "        return output\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            inputs is a LongTensor of shape (batch_size, max_seq_length)\n",
        "            \n",
        "        Returns:\n",
        "            logits of shape (batch_size, vocab_size)\n",
        "        \"\"\"\n",
        "        # Escreva seu código aqui.\n",
        "        batch_size = inputs.shape[0]\n",
        "\n",
        "        X_emb = self.embedding_layer(inputs)\n",
        "        X = X_emb + self.positional_embeddings.weight\n",
        "\n",
        "        #mask_padc = pad_mask & causal_mask\n",
        "        pad_mask = inputs != self.pad_token_id\n",
        "        mask_padc = (inputs != self.pad_token_id).unsqueeze(1) & torch.tril(torch.ones((self.max_seq_length, self.max_seq_length))).bool().to(device)\n",
        "        #print(f'pad_mask shape: {pad_mask.unsqueeze(1).shape}')\n",
        "\n",
        "        for i in range(self.n_layers):\n",
        "            q = self.W_q(X.unsqueeze(1))\n",
        "            #q = self.W_q(X)\n",
        "            k = self.W_k(X)\n",
        "            v = self.W_v(X)\n",
        "\n",
        "            new_x = self.Attention(q, k, v, mask_padc)\n",
        "            \n",
        "            X = self.W_o(new_x)\n",
        "\n",
        "        logits = self.linear1(X.view(batch_size,-1)) \n",
        "        logits = self.relu1(logits)\n",
        "        logits = self.linear2(logits)\n",
        "\n",
        "        #logits = self.feed_forward(X.reshape(len(inputs),-1))\n",
        "\n",
        "        logits = logits.reshape(X.shape[0], self.max_seq_length, self.vocab_size)\n",
        "        \n",
        "        return logits"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rm6_PTH2i98e"
      },
      "source": [
        "## Teste o modelo com um exemplo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        },
        "id": "RwnxfZlrZoT_",
        "outputId": "deddf857-3855-42bb-c877-95b5035502f3"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-22-b727109e4ff7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mn_layers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mpad_token_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpad_token_id\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m ).to(device)\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0msample_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mto\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    905\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_complex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    906\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 907\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    908\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    909\u001b[0m     def register_backward_hook(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    576\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    577\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 578\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    579\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    580\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    599\u001b[0m             \u001b[0;31m# `with torch.no_grad():`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 601\u001b[0;31m                 \u001b[0mparam_applied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    602\u001b[0m             \u001b[0mshould_use_set_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    603\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mshould_use_set_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mconvert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    903\u001b[0m                 return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None,\n\u001b[1;32m    904\u001b[0m                             non_blocking, memory_format=convert_to_format)\n\u001b[0;32m--> 905\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_complex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    906\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    907\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.76 GiB total capacity; 13.34 GiB already allocated; 21.75 MiB free; 13.35 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
          ]
        }
      ],
      "source": [
        "embedding_dim = 10\n",
        "batch_size = 1024\n",
        "\n",
        "model = LanguageModel(\n",
        "    vocab_size=tokenizer.vocab_size,\n",
        "    max_seq_length=max_seq_length,\n",
        "    dim=64,\n",
        "    n_layers=2,\n",
        "    pad_token_id=tokenizer.pad_token_id,\n",
        ").to(device)\n",
        "\n",
        "sample_input, _ = next(iter(DataLoader(training_dataset)))\n",
        "sample_input = sample_input.to(device)\n",
        "sample_output = model(sample_input)\n",
        "print(f'sample_input.shape: {sample_input.shape}')\n",
        "print(f'sample_output.shape: {sample_output.shape}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j1Ghr97MzeGF",
        "outputId": "9d6680aa-d7ef-49f2-e4cb-14b1f1521fdf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "batch de inputs: tensor([[  101, 20100,  2308,  3074,  1089,   481,   117,   146,  1189],\n",
            "        [  125, 13254,   143,   122, 18073, 22281,   179,   695,   923]])\n",
            "batch de targets: tensor([[20100,  2308,  3074,  1089,   481,   117,   146,  1189,   125],\n",
            "        [13254,   143,   122, 18073, 22281,   179,   695,   923,   320]])\n"
          ]
        }
      ],
      "source": [
        "train_input_ids, train_target_ids = next(iter(DataLoader(training_dataset, batch_size=2)))\n",
        "\n",
        "print(f'batch de inputs: {train_input_ids}')\n",
        "print(f'batch de targets: {train_target_ids}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I3Vh6B-VkA01",
        "outputId": "421a5ea7-d38f-4d43-dd98-41f7f9813337"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of model parameters: 19122048\n"
          ]
        }
      ],
      "source": [
        "num_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "print(f'Number of model parameters: {num_params}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8nhbUVsYnVAp"
      },
      "source": [
        "## Assert da Perplexidade\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        },
        "id": "gbMP8VAUncfX",
        "outputId": "082dc198-3aa3-42f7-97a1-39bec70c27a3"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-42752a15506b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0mtrain_target_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_target_ids\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_input_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0mmy_perplexity\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mperplexity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_target_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_token_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpad_token_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-16-48d6b8fa3142>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    111\u001b[0m             \u001b[0mq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mW_q\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m             \u001b[0;31m#q = self.W_q(X)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m             \u001b[0mk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mW_k\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m             \u001b[0mv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mW_v\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 2.15 GiB (GPU 0; 14.76 GiB total capacity; 13.33 GiB already allocated; 21.75 MiB free; 13.35 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
          ]
        }
      ],
      "source": [
        "random.seed(123)\n",
        "np.random.seed(123)\n",
        "torch.manual_seed(123)\n",
        "\n",
        "\n",
        "def perplexity(logits, target, ignore_token_id: int):\n",
        "    \"\"\"\n",
        "    Computes the perplexity.\n",
        "\n",
        "    Args:\n",
        "        logits: a FloatTensor of shape (batch_size, seq_length, vocab_size)\n",
        "        target: a LongTensor of shape (batch_size, seq_length)\n",
        "\n",
        "    Returns:\n",
        "        A float corresponding to the perplexity\n",
        "    \"\"\"\n",
        "    logits = logits.reshape(-1, logits.shape[-1])\n",
        "    target = target.reshape(-1)\n",
        "    loss = nn.functional.cross_entropy(logits, target, reduction='mean', ignore_index=ignore_token_id)\n",
        "    return torch.exp(loss)\n",
        "\n",
        "\n",
        "n_examples = 1000\n",
        "\n",
        "train_input_ids, train_target_ids = next(iter(DataLoader(training_dataset, batch_size=n_examples)))\n",
        "train_input_ids = train_input_ids.to(device)\n",
        "train_target_ids = train_target_ids.to(device)\n",
        "\n",
        "logits = model(train_input_ids)\n",
        "\n",
        "my_perplexity = perplexity(logits=logits, target=train_target_ids, ignore_token_id=tokenizer.pad_token_id)\n",
        "\n",
        "print(f'my perplexity:              {int(my_perplexity)}')\n",
        "print(f'correct initial perplexity: {tokenizer.vocab_size}')\n",
        "\n",
        "assert math.isclose(my_perplexity, tokenizer.vocab_size, abs_tol=7000)\n",
        "print('Passou o no assert da perplexidade')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_target_ids.shape\n",
        "logits.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VQ53vnEWj6rv",
        "outputId": "7f14dd4a-0a22-4fc3-ef9a-112c8499f3ad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1000, 9, 29794])"
            ]
          },
          "metadata": {},
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KiJtrsqPnE_l"
      },
      "source": [
        "## Laço de Treinamento e Validação"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "13p6y-bXPzKK",
        "outputId": "4126efde-94eb-43f0-e279-073057615730"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 steps; 0 examples so far; train ppl: 29784.45, valid ppl: 29779.49\n",
            "100 steps; 51200 examples so far; train ppl: 9090.19, valid ppl: 2914.45\n",
            "200 steps; 102400 examples so far; train ppl: 1905.40, valid ppl: 2135.18\n",
            "300 steps; 153600 examples so far; train ppl: 1424.38, valid ppl: 1873.15\n",
            "400 steps; 204800 examples so far; train ppl: 1135.86, valid ppl: 1643.91\n",
            "500 steps; 256000 examples so far; train ppl: 954.25, valid ppl: 1457.58\n",
            "600 steps; 307200 examples so far; train ppl: 822.25, valid ppl: 1298.71\n",
            "700 steps; 358400 examples so far; train ppl: 680.35, valid ppl: 1203.24\n",
            "800 steps; 409600 examples so far; train ppl: 586.74, valid ppl: 1119.53\n",
            "900 steps; 460800 examples so far; train ppl: 517.20, valid ppl: 1056.72\n",
            "1000 steps; 512000 examples so far; train ppl: 434.05, valid ppl: 1002.35\n",
            "1100 steps; 563200 examples so far; train ppl: 371.23, valid ppl: 975.71\n",
            "1200 steps; 614400 examples so far; train ppl: 331.17, valid ppl: 964.74\n",
            "1300 steps; 665600 examples so far; train ppl: 279.26, valid ppl: 934.21\n",
            "1400 steps; 716800 examples so far; train ppl: 236.00, valid ppl: 989.83\n",
            "1500 steps; 768000 examples so far; train ppl: 208.80, valid ppl: 1032.49\n",
            "1600 steps; 819200 examples so far; train ppl: 173.75, valid ppl: 986.92\n",
            "1700 steps; 870400 examples so far; train ppl: 144.15, valid ppl: 1108.66\n",
            "1800 steps; 921600 examples so far; train ppl: 124.72, valid ppl: 1280.79\n",
            "1900 steps; 972800 examples so far; train ppl: 103.59, valid ppl: 1260.99\n"
          ]
        }
      ],
      "source": [
        "# com gpu\n",
        "# laço com save \n",
        "\n",
        "compare=float('inf')\n",
        "\n",
        "max_examples = 1_000_000\n",
        "eval_every_steps = 100\n",
        "lr = 3e-4\n",
        "\n",
        "embedding_dim = 256\n",
        "batch_size = 512\n",
        "model = LanguageModel(\n",
        "    vocab_size=tokenizer.vocab_size,\n",
        "    max_seq_length=max_seq_length,\n",
        "    dim=embedding_dim,\n",
        "    n_layers=2,\n",
        "    pad_token_id=tokenizer.pad_token_id,\n",
        ").to(device)\n",
        "\n",
        "train_loader = DataLoader(training_dataset, batch_size=batch_size, shuffle=True, drop_last=True)\n",
        "validation_loader = DataLoader(valid_dataset, batch_size=batch_size)\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "\n",
        "\n",
        "def train_step(input_ids, target_ids):\n",
        "    model.train()\n",
        "    model.zero_grad()\n",
        "    logits = model(input_ids)\n",
        "    logits = logits.reshape(-1, logits.shape[-1])\n",
        "    target_ids = target_ids.reshape(-1)\n",
        "    loss = nn.functional.cross_entropy(logits, target_ids, ignore_index=model.pad_token_id)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    return loss.item()\n",
        "\n",
        "\n",
        "def validation_step(input_ids, target_ids):\n",
        "    model.eval()\n",
        "    logits = model(input_ids)\n",
        "    logits = logits.reshape(-1, logits.shape[-1])\n",
        "    target_ids = target_ids.reshape(-1)\n",
        "    loss = nn.functional.cross_entropy(logits, target_ids, ignore_index=model.pad_token_id)\n",
        "    return loss.item()\n",
        "\n",
        "\n",
        "train_losses = []\n",
        "n_examples = 0\n",
        "step = 0\n",
        "while n_examples < max_examples:\n",
        "    for input, target in train_loader:\n",
        "        loss = train_step(input.to(device), target.to(device)) \n",
        "        train_losses.append(loss)\n",
        "        \n",
        "        if step % eval_every_steps == 0:\n",
        "            train_ppl = np.exp(np.average(train_losses))\n",
        "\n",
        "            with torch.no_grad():\n",
        "                valid_ppl = np.exp(np.average([\n",
        "                    validation_step(input.to(device), target.to(device))\n",
        "                    for input, target in validation_loader]))\n",
        "                \n",
        "                if valid_ppl<compare:\n",
        "                    compare=valid_ppl\n",
        "                    torch.save(model, \"/content/drive/MyDrive/Intro ao Aprendizado Profundo/Trabalho10/modelos_salvos/\"+f\"model_{max_examples/1000000}ex_{embedding_dim}embdim.pt\")\n",
        "                    with open(\"/content/drive/MyDrive/Intro ao Aprendizado Profundo/Trabalho10/modelos_salvos/\"+f\"model_{max_examples/1000000}ex_{embedding_dim}embdim.txt\", 'w') as f:\n",
        "                      lines = [f'batch size = {batch_size}', \n",
        "                                f'embedding dim = {embedding_dim}', \n",
        "                                f'max examples = {max_examples}', \n",
        "                                f'learning rate = {lr}', \n",
        "                                f'max_examples = {max_examples}', \n",
        "                                f'train PPL = {train_ppl}',\n",
        "                                f'validation PPL = {valid_ppl}',\n",
        "                                f'best values at {n_examples} examples']\n",
        "                      f.writelines('\\n'.join(lines))\n",
        "                    f.close()\n",
        "\n",
        "            print(f'{step} steps; {n_examples} examples so far; train ppl: {train_ppl:.2f}, valid ppl: {valid_ppl:.2f}')\n",
        "            train_losses = []\n",
        "\n",
        "        n_examples += len(input)  # Increment of batch size\n",
        "        step += 1\n",
        "        if n_examples >= max_examples:\n",
        "            break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VgdNymJdNPXP"
      },
      "source": [
        "## Avaliação final no dataset de teste\n",
        "\n",
        "\n",
        "Bonus: o modelo com menor perplexidade no dataset de testes ganhará 0.5 ponto na nota final."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nxN5YytzZ7Tn",
        "outputId": "abcb495b-f3e7-43c4-a09a-29774db5b2a2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test perplexity: 1599.0058759514488\n"
          ]
        }
      ],
      "source": [
        "test_loader = DataLoader(test_dataset, batch_size=64)\n",
        "\n",
        "with torch.no_grad():\n",
        "    test_ppl = np.exp(np.average([\n",
        "        validation_step(test_input_ids.to(device), test_target_ids.to(device))\n",
        "        for test_input_ids, test_target_ids in test_loader\n",
        "    ]))\n",
        "\n",
        "print(f'test perplexity: {test_ppl}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BHvEs8mPszy_"
      },
      "source": [
        "## Teste seu modelo com uma sentença\n",
        "\n",
        "Escolha uma sentença gerada pelo modelo que ache interessante."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-CFElf4tsytW",
        "outputId": "34027d66-5feb-46f0-e59d-8014dfad41cf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Eu gosto de comer pizza pois me faz, a\n",
            "Eu gosto de comer pizza pois me faz, a partir\n",
            "Eu gosto de comer pizza pois me faz, a partir de\n",
            "Eu gosto de comer pizza pois me faz, a partir de.\n",
            "Eu gosto de comer pizza pois me faz, a partir de. Art\n",
            "Eu gosto de comer pizza pois me faz, a partir de. Art,\n",
            "Eu gosto de comer pizza pois me faz, a partir de. Art, a\n",
            "Eu gosto de comer pizza pois me faz, a partir de. Art, a,\n",
            "Eu gosto de comer pizza pois me faz, a partir de. Art, a, de\n",
            "Eu gosto de comer pizza pois me faz, a partir de. Art, a, de ras\n",
            "Eu gosto de comer pizza pois me faz, a partir de. Art, a, de ras,\n",
            "Eu gosto de comer pizza pois me faz, a partir de. Art, a, de ras, o\n",
            "Eu gosto de comer pizza pois me faz, a partir de. Art, a, de ras, o resultado\n",
            "Eu gosto de comer pizza pois me faz, a partir de. Art, a, de ras, o resultado,\n",
            "Eu gosto de comer pizza pois me faz, a partir de. Art, a, de ras, o resultado, a\n",
            "Eu gosto de comer pizza pois me faz, a partir de. Art, a, de ras, o resultado, a população\n",
            "Eu gosto de comer pizza pois me faz, a partir de. Art, a, de ras, o resultado, a população de\n",
            "Eu gosto de comer pizza pois me faz, a partir de. Art, a, de ras, o resultado, a população de autorização\n",
            "Eu gosto de comer pizza pois me faz, a partir de. Art, a, de ras, o resultado, a população de autorização,\n",
            "Eu gosto de comer pizza pois me faz, a partir de. Art, a, de ras, o resultado, a população de autorização, a\n"
          ]
        }
      ],
      "source": [
        "prompt = 'Eu gosto de comer pizza pois me faz,'\n",
        "max_output_tokens = 20\n",
        "model.eval()\n",
        "\n",
        "for _ in range(max_output_tokens):\n",
        "    input_ids = tokenize(text=prompt, tokenizer=tokenizer)\n",
        "    input_ids_truncated = input_ids[-max_seq_length:]  # Usamos apenas os últimos <max_seq_length> tokens como entrada para o modelo.\n",
        "    logits = model(torch.LongTensor([input_ids_truncated]).to(device))\n",
        "    logits = logits[:, -1, :]  # Usamos apenas o ultimo token da sequencia\n",
        "    # Ao usarmos o argmax, a saída do modelo em cada passo é o token de maior probabilidade.\n",
        "    # Isso se chama decodificação gulosa (greedy decoding).\n",
        "    predicted_id = torch.argmax(logits).item()\n",
        "    input_ids += [predicted_id]  # Concatenamos a entrada com o token escolhido nesse passo.\n",
        "    prompt = tokenizer.decode(input_ids)\n",
        "    print(prompt)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nGdxlXhGq7Ua"
      },
      "source": [
        "## Bonus 1\n",
        "Quem conseguir a menor perplexidade no dataset de testes ganha 0.5 ponto na média final.\n",
        "\n",
        "## Bonus 2\n",
        "Qual é a complexidade (em notação O-grande) da função de geração de texto acima?\n",
        "\n",
        "Quem responder corretamente a pergunta acima e deixar a função com menor complexidade ganha 0.5 ponto na média final."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zKGcXeZVP36Q",
        "outputId": "26fc5a14-1558-46fb-d72b-827a78e23884"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dzX4bYXRFRZd"
      },
      "source": [
        "# Rascunhos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7DcY3AwQFSxs"
      },
      "outputs": [],
      "source": [
        "rint(f'token de PAD do BERT:{tokenizer.pad_token}')\n",
        "\n",
        "pad = '[PAD]'\n",
        "print(f'número que indica o toke de PAD: {tokenizer.vocab[pad]}')\n",
        "\n",
        "dummy_texts = ['Eu gosto de correr', 'Ela gosta muito de comer pizza']\n",
        "print(f'dummy_texts: {dummy_texts}')\n",
        "max_seq_length = 3\n",
        "dummy_dataset = MyDataset(texts=dummy_texts, tokenizer=tokenizer, max_seq_length=max_seq_length)\n",
        "dummy_loader = DataLoader(dummy_dataset, batch_size=6, shuffle=False)\n",
        "\n",
        "print(f'dummy_dataset: {dummy_dataset}')\n",
        "print(f'dummy_loader: {dummy_loader}')\n",
        "\n",
        "first_batch_input, first_batch_target = next(iter(dummy_loader))\n",
        "print(f'batch_input: {first_batch_input}')\n",
        "print(f'batch_target: {first_batch_target}')\n",
        "\n",
        "tokens_ids = tokenize(dummy_texts[0], tokenizer)\n",
        "tensor_empty = torch.zeros(max_seq_length, dtype=torch.int32)\n",
        "print(f'empty tensor: {tensor_empty}')\n",
        "\n",
        "after_sum = tensor_empty + first_batch_input[0] \n",
        "print(f'tensor depois da soma: {after_sum}')\n",
        "\n",
        "\n",
        "#def __init__(self, texts: List[str], tokenizer, max_seq_length: int):\n",
        "#self.tokensIds_n = []\n",
        "#self.y = []\n",
        "\n",
        "texts = dummy_texts\n",
        "tokensIds_n = []\n",
        "max_seq_length = 9\n",
        "token_cls = torch.tensor(tokenizer.vocab['[CLS]'], dtype=torch.int32)\n",
        "for text in tqdm_notebook(texts):\n",
        "  tokens_ids = tokenize(text, tokenizer)\n",
        "  # desconsiderar parte que tira tamanhos diferentes\n",
        "  print(f'len token_ids:{len(tokens_ids)}')\n",
        "  print(f'tokens_ids do texto {text}: {tokens_ids}')\n",
        "  #if len(tokens_ids) < max_seq_length:\n",
        "   # for i in range(max_seq_length):\n",
        "   #   tokensIds_n_temp = []\n",
        "   #   tokensIds_n_temp.append(tokens_ids[i:max_seq_length])\n",
        "   #   p1d = (0, max_seq_length - len(tokensIds_n_temp))\n",
        "   #   out = nn.functional.pad(tokensIds_n_temp, p1d, \"constant\", 0)\n",
        "   #   tokensIds_n.append(out)\n",
        "\n",
        "  if len(tokens_ids) < max_seq_length:\n",
        "    #tokenid_temp = torch.tensor(tokens_ids[0:max_seq_length])\n",
        "    tokenid_temp_cat = torch.cat((token_cls.unsqueeze(dim=-1), torch.tensor(tokens_ids[0:max_seq_length])))\n",
        "    print(f'tokenid_temp_cat: {torch.cat((token_cls.unsqueeze(dim=-1), tokenid_temp_cat))}')\n",
        "    tokensIds_n.append(tokenid_temp_cat)\n",
        "\n",
        "  else:\n",
        "    for i in range(max_seq_length):\n",
        "      tokenid_temp = torch.tensor(tokens_ids[i:max_seq_length])\n",
        "      #tokenid_temp_cat = torch.cat(token_cls,tokenid_temp), dim=0)\n",
        "      #tokenid_temp_cat = torch.cat((token_cls.unsqueeze(dim=-1), tokenid_temp))\n",
        "      tokensIds_n.append(torch.cat((token_cls.unsqueeze(dim=-1), tokenid_temp)))\n",
        "      print(f'tokenid_temp_cat: {torch.cat((token_cls.unsqueeze(dim=-1), tokenid_temp))}')\n",
        "      #tokensIds_n.append(torch.cat((token_cls.unsqueeze(dim=-1), tokenid_temp)))\n",
        "\n",
        "print(f'lista de tokens ids: {tokensIds_n}')\n",
        "for j, s in enumerate(tokensIds_n):\n",
        "  #print(f'j: {j}')\n",
        "  #print(f's: {s}')\n",
        "  if len(s) < max_seq_length:\n",
        "    s_torch = torch.tensor(s)\n",
        "    p1d = (0, max_seq_length - len(s))\n",
        "    #padded = nn.functional.pad(s_torch, p1d, \"constant\", 0)\n",
        "    #print(f'padded: {padded}')\n",
        "    tokensIds_n[j] = nn.functional.pad(s_torch, p1d, \"constant\", 0)\n",
        "          #self.y.append(tokens_ids[i+context_size])\n",
        "\n",
        "tokensIds_n = torch.stack(tokensIds_n, 0)\n",
        "print(f'token ids batch: {tokensIds_n}')\n",
        "\n",
        "# definir batch de target\n",
        "tensor_zero = torch.tensor(0)\n",
        "token_ids_target = torch.empty(len(texts), max_seq_length, dtype=torch.int32)\n",
        "j=0\n",
        "for i in tokensIds_n:\n",
        "  #token_tensor = i[1:]\n",
        "  #print(f'tonken shifted: {token_tensor}')\n",
        "  tokenid_temp_cat = torch.cat((i[1:], tensor_zero.unsqueeze(dim=-1)))\n",
        "  token_ids_target[j] = tokenid_temp_cat\n",
        "  j+=1\n",
        "  #target = torch.stack((tokenid_temp_cat, tokenid_temp_cat))\n",
        "\n",
        "#print(f'tokens id: {tokensIds_n}')\n",
        "#print(f'token ids target: {token_ids_target}')\n",
        "\n",
        "#traget = torch.LongTensor(token_ids_target)\n",
        "print(f'target: {token_ids_target}')\n",
        "print(f'texts: {texts}')\n",
        "#print(f'tokens id: {tokensIds_n}')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "ex10_attention_causal_mask.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "469d829b091c415fbc1df6af5a156f52": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_026d500169cd4b3286077c782974d22e",
              "IPY_MODEL_2180b993e80b40d9ad50f89d11f55670",
              "IPY_MODEL_112cda068f2f42ddb17dbfd6af55c6ee"
            ],
            "layout": "IPY_MODEL_4ebffc8f8b0e47f7ad1c0acbde55e5c0"
          }
        },
        "026d500169cd4b3286077c782974d22e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_81efbe5f372e47ed8466b0ad6c809fe1",
            "placeholder": "​",
            "style": "IPY_MODEL_582526328d2c43cfba5bef998eefaf96",
            "value": "Downloading: 100%"
          }
        },
        "2180b993e80b40d9ad50f89d11f55670": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bdf2718ed9584dcf8af28a64172a1017",
            "max": 209528,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ec8fc46745c74caa84e2355ce40700ed",
            "value": 209528
          }
        },
        "112cda068f2f42ddb17dbfd6af55c6ee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_63bc706e98254b879e6b9106b4a39e88",
            "placeholder": "​",
            "style": "IPY_MODEL_d452f6bff54c4b2584dbc2230e8653b3",
            "value": " 205k/205k [00:00&lt;00:00, 9.41kB/s]"
          }
        },
        "4ebffc8f8b0e47f7ad1c0acbde55e5c0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "81efbe5f372e47ed8466b0ad6c809fe1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "582526328d2c43cfba5bef998eefaf96": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bdf2718ed9584dcf8af28a64172a1017": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ec8fc46745c74caa84e2355ce40700ed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "63bc706e98254b879e6b9106b4a39e88": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d452f6bff54c4b2584dbc2230e8653b3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ccd575a5c08349148876f656b0120151": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6133f2f492224a9086f86d2235c895bc",
              "IPY_MODEL_37aa74ff8e174730b8e9a38ebad2f973",
              "IPY_MODEL_f3c5b23a935f4f36a8bc417d37ff9810"
            ],
            "layout": "IPY_MODEL_6913f4eae703454b8f4941b41dc4fbbf"
          }
        },
        "6133f2f492224a9086f86d2235c895bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f5a196b261ef43d8926e885f76aefcff",
            "placeholder": "​",
            "style": "IPY_MODEL_146a65801d8442139e71647c8fbaee20",
            "value": "Downloading: 100%"
          }
        },
        "37aa74ff8e174730b8e9a38ebad2f973": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_57bb0716cf0247619f1998e7ab759e94",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_160e78b755bc4adf88885e9d4adb2928",
            "value": 2
          }
        },
        "f3c5b23a935f4f36a8bc417d37ff9810": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f91e1bd87c224966bc1bd69d8f158d88",
            "placeholder": "​",
            "style": "IPY_MODEL_5f624b6948fd49fb82f81771891fb887",
            "value": " 2.00/2.00 [00:00&lt;00:00, 33.5B/s]"
          }
        },
        "6913f4eae703454b8f4941b41dc4fbbf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f5a196b261ef43d8926e885f76aefcff": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "146a65801d8442139e71647c8fbaee20": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "57bb0716cf0247619f1998e7ab759e94": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "160e78b755bc4adf88885e9d4adb2928": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f91e1bd87c224966bc1bd69d8f158d88": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5f624b6948fd49fb82f81771891fb887": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b5b920fd4a6a449999b313c56aea0028": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_654b49da395d4049bba857d50c34883a",
              "IPY_MODEL_7cc4ba677b334b81b6092dec5c1903a9",
              "IPY_MODEL_15bc9c7c17a3476c85cb75b8259f51df"
            ],
            "layout": "IPY_MODEL_7d36c8c53c2f450ab97a7d8b18f6a1d4"
          }
        },
        "654b49da395d4049bba857d50c34883a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fa6f41d376ff4e27be37508d89c22d25",
            "placeholder": "​",
            "style": "IPY_MODEL_1aee1a1f641e4448b8c2cb8b5f4acad9",
            "value": "Downloading: 100%"
          }
        },
        "7cc4ba677b334b81b6092dec5c1903a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5e0d9b02d5544c798dc8f5d5ebb0bc2f",
            "max": 112,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_be7f29d65e14485eb74832eca163cd51",
            "value": 112
          }
        },
        "15bc9c7c17a3476c85cb75b8259f51df": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8211acc3a6f34e95a8d414b5fe80c24a",
            "placeholder": "​",
            "style": "IPY_MODEL_723b019276ed4e2bb80fbb5f2fd02737",
            "value": " 112/112 [00:00&lt;00:00, 1.02kB/s]"
          }
        },
        "7d36c8c53c2f450ab97a7d8b18f6a1d4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fa6f41d376ff4e27be37508d89c22d25": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1aee1a1f641e4448b8c2cb8b5f4acad9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5e0d9b02d5544c798dc8f5d5ebb0bc2f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "be7f29d65e14485eb74832eca163cd51": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8211acc3a6f34e95a8d414b5fe80c24a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "723b019276ed4e2bb80fbb5f2fd02737": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d1cdc514009e43ffad8fedb83e3395c7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9e85c28c5b8147938e33090b296629d7",
              "IPY_MODEL_4ffc3f6ff2174ed48d3872eaaee6ef21",
              "IPY_MODEL_e8c587241d14400ea298911c352c8557"
            ],
            "layout": "IPY_MODEL_e72f8579fbd4441f92bae305de84a3a2"
          }
        },
        "9e85c28c5b8147938e33090b296629d7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8495d49fdca241c1905eb8916d99de0e",
            "placeholder": "​",
            "style": "IPY_MODEL_12079446e9cf4f73bd1ee19fb5930611",
            "value": "Downloading: 100%"
          }
        },
        "4ffc3f6ff2174ed48d3872eaaee6ef21": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f9e63bf9ee2246628fb975187dd10de8",
            "max": 43,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a719adc95f6e4cf7baa71068b5480956",
            "value": 43
          }
        },
        "e8c587241d14400ea298911c352c8557": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d2367d1ec3c2422cb0f6d8cf0c38cee7",
            "placeholder": "​",
            "style": "IPY_MODEL_46c2c396d77c41759fbb31c44e99dc1f",
            "value": " 43.0/43.0 [00:00&lt;00:00, 564B/s]"
          }
        },
        "e72f8579fbd4441f92bae305de84a3a2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8495d49fdca241c1905eb8916d99de0e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "12079446e9cf4f73bd1ee19fb5930611": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f9e63bf9ee2246628fb975187dd10de8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a719adc95f6e4cf7baa71068b5480956": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d2367d1ec3c2422cb0f6d8cf0c38cee7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "46c2c396d77c41759fbb31c44e99dc1f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8aa4170b33204405b01fc68db3b960c3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_875190f4b8e74b2e856187625e7b93d9",
              "IPY_MODEL_f0e09963c89b42e1a5202891380515d2",
              "IPY_MODEL_5785b52c256e43ae8908e747b66e2a30"
            ],
            "layout": "IPY_MODEL_ce3e0683d3a649c48a062d88d2753171"
          }
        },
        "875190f4b8e74b2e856187625e7b93d9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bbb6942286ca44219eabe5e3ca83dc19",
            "placeholder": "​",
            "style": "IPY_MODEL_cfeb8653f51d4c4db0e290ea19b70c96",
            "value": "Downloading: 100%"
          }
        },
        "f0e09963c89b42e1a5202891380515d2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_711425a7902d4e319cf66a71bd8c736c",
            "max": 647,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a78adcf4b5244c9daae9f3c0135b3539",
            "value": 647
          }
        },
        "5785b52c256e43ae8908e747b66e2a30": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_35b3c6968f3345af914a588110abf9ab",
            "placeholder": "​",
            "style": "IPY_MODEL_80870b89b7e24f30bdb31fa891e3d7f7",
            "value": " 647/647 [00:00&lt;00:00, 6.47kB/s]"
          }
        },
        "ce3e0683d3a649c48a062d88d2753171": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bbb6942286ca44219eabe5e3ca83dc19": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cfeb8653f51d4c4db0e290ea19b70c96": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "711425a7902d4e319cf66a71bd8c736c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a78adcf4b5244c9daae9f3c0135b3539": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "35b3c6968f3345af914a588110abf9ab": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "80870b89b7e24f30bdb31fa891e3d7f7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}